{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyhfho1b/TOoHbCOuQjSX2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yuto-Koga/my-macro-project/blob/main/Untitled37.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qP4wV17wD3nF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "Tensor = torch.Tensor\n",
        "\n",
        "# the code of financial acceletor model\n",
        "# ---------- 1) Household Utility (CES in c, separable disutility of hours) (17) ----------\n",
        "class HouseholdUtility:\n",
        "    def __init__(self,beta=0.99):\n",
        "        self.beta = torch.tensor(beta, dtype=torch.double)\n",
        "\n",
        "    def C_next(self, C: Tensor, C_next: Tensor, R: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        c: (3,)  consumption per sector [c1,c2,c3]\n",
        "        h: (3,)  hours per sector      [h1,h2,h3]\n",
        "        N: (3,)  employment shares     [N1,N2,N3]  (使い方は任意だが、重み付けに利用)\n",
        "        lam: scalar weight on disutility\n",
        "        \"\"\"\n",
        "        C = C.clamp_min(1e-8)\n",
        "        R = R.clamp_min(0.0)\n",
        "\n",
        "\n",
        "\n",
        "        return self.beta * R * C\n",
        "\n",
        "# ---------- 2)  labor supply condition (18)----------\n",
        "class laborsupply:\n",
        "    def __init__(self,zeta==0.9):\n",
        "        self.zeta = torch.tensor(zeta, dtype=torch.double)\n",
        "\n",
        "    def W(self, C: Tensor, H: Tensor, W: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "\n",
        "        \"\"\"\n",
        "        W = C.clamp_min(1e-8)\n",
        "        C = R.clamp_min(0.0)\n",
        "        H = H.clamp_min(1e-8)\n",
        "\n",
        "\n",
        "\n",
        "        return C * self.zeta /(1-H)\n",
        "\n",
        " # ---------- 3) Capital sotck dynamics (19)----------\n",
        "class capitalstock:\n",
        "    def __init__(self, delta=0.9, kappa = 0.5 ):\n",
        "        self.delta = torch.tensor(delta, dtype=torch.double)\n",
        "        self.kappa = torch.tensor(kappa, dtype=torch.double)\n",
        "    def K(self, K: Tensor, I: Tensor, u: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "       K(t+1) = (1-dleta)K + kappa/2(I/K - delta)**2 * K\n",
        "        \"\"\"\n",
        "        K = K.clamp_min(1e-12)\n",
        "        I = I.clamp_min(1e-12)\n",
        "\n",
        "        return (1-self.delta)K + self.kappa/2 * (I/K - self.delta)**2 * K\n",
        "\n",
        "\n",
        "# ---------- 4) Tobin's Q (20)----------\n",
        "class capitalprice:\n",
        "    def __init__(self, delta=0.9, kappa = 0.5 ):\n",
        "        self.delta = torch.tensor(delta, dtype=torch.double)\n",
        "        self.kappa = torch.tensor(kappa, dtype=torch.double)\n",
        "    def q(self, K: Tensor, I: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "       Q_t = (kappa * (I/K - delta) * K)**(-1)\n",
        "        \"\"\"\n",
        "        K = K.clamp_min(1e-12)\n",
        "        I = I.clamp_min(1e-12)\n",
        "        return (self.kappa * (I/K - self.delta) * K)**(-1)\n",
        "\n",
        "\n",
        "# ---------- 5) the expected return on holding capital (21)----------\n",
        "class capitalprice:\n",
        "    def __init__(self, delta=0.9, R = 0.1 ):\n",
        "        self.delta = torch.tensor(delta, dtype=torch.double)\n",
        "        self.R = torch.tensor(R, dtype=torch.double)\n",
        "    def Rk_next(self, R_next: Tensor, Q_next: Tensor, Q: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "       Q_t = (kappa * (I/K - delta) * K)**(-1)\n",
        "        \"\"\"\n",
        "        Q = Q.clamp_min(1e-12)\n",
        "        Q_next = Q_next.clamp_min(1e-12)\n",
        "        R_next = R_next.clamp_min(1e-12)\n",
        "        return (self.R * R_next + (1- self.deta) * Q_next) / Q\n",
        "\n",
        "\n",
        "# ---------- 6) Entrepreneurial Sector (25)----------\n",
        "class production:\n",
        "    def __init__(self, theta = 0.5, ipsilon=0.2 ):\n",
        "        self.theta = torch.tensor(theta, dtype=torch.double)\n",
        "        self.ipsilon = torch.tensor(ipsilon, dtype=torch.double)\n",
        "\n",
        "\n",
        "\n",
        "    def d(self, sum: Tensor, d_(t-1): Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "\n",
        "        \"\"\"\n",
        "        sum = sum.clamp_min(1e-12)\n",
        "        d_t1 = d_t1.clamp_min(1e-12)\n",
        "        return (1-self.theta) * sum**(-self.ipsilon) + self.theta * sum**(self.ipsilon) * d_(t-1)\n",
        "\n",
        "# ---------- 7) optimal relative reset price----------\n",
        "class reset price:\n",
        "    def __init__(self,  ipsilon=0.2 ):\n",
        "        self.ipsilon = torch.tensor(ipsilon, dtype=torch.double)\n",
        "\n",
        "\n",
        "\n",
        "    def sum(self,x1: Tensor, x2: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "\n",
        "        \"\"\"\n",
        "        sum = sum.clamp_min(1e-12)\n",
        "        x1 = x1.clamp_min(1e-12)\n",
        "        x2 = x2.clamp_min(1e-12)\n",
        "        return (self.ipsilon * x1) / (x2*(self.ipsilon-1))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "# ---------- 7) production function (24) ----------\n",
        "class production:\n",
        "    def __init__(self, Omega=0.9, alpha=0.2):\n",
        "        self.Omega = torch.tensor(Omega, dtype=torch.double)\n",
        "        self.alpha = torch.tensor(alpha, dtype=torch.double)\n",
        "    def Y(self, h: Tensor, h_e: Tensor, K; Tensor, A: Tensor, d: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "       h**(Omega) * h_e**(1-Omega)\n",
        "        \"\"\"\n",
        "        h  = h.clamp_min(1e-12)\n",
        "        h_e = h_e.clamp_min(1e-12)\n",
        "        K = K.clamp_min(1e-12)\n",
        "        A = A.clamp_min(1e-12)\n",
        "        d = d.clamp_min(1e-12)\n",
        "        return A * (K**self.alpha) * (h**(self.Omega * (1- self.alpha))) * (h_e**((1-self.Omega)*(1-self.alpha))) / d\n",
        "\n",
        "# ---------- 4) expected gross return  ----------\n",
        "class greturn:\n",
        "    def __init__(self, delta=0.9, a = 0.5 ):\n",
        "        self.delta = torch.tensor(delta, dtype=torch.double)\n",
        "        self.a = torch.tensor(a, dtype=torch.double)\n",
        "\n",
        "    def Rk_next(self,\n",
        "               K_next: Tensor,         # t の資本\n",
        "               X_next: Tensor,      # t+1 の労働（または利用率）\n",
        "               q_t: Tensor,         # t の q\n",
        "               q_next: Tensor\n",
        "               Y_t; Tensor       # t+1 の q\n",
        "               ) -> Tensor:\n",
        "\n",
        " 　　　 K_t = K_t.clamp_min(1e-12)\n",
        "        h_next = h_next.clamp_min(1e-12)\n",
        "\n",
        "        mpk_next = self.alpha * Y_t / (X_next * K_next)\n",
        "        numer = (1.0 - self.delta) * q_next\n",
        "        return numer / q_t.clamp_min(1e-12)\n",
        "\n",
        "# ---------- 5) labor supply----------\n",
        "class laborsupply:\n",
        "    def __init__(self, Omega=0.9):\n",
        "        self.Omega = torch.tensor(Omega, dtype=torch.double)\n",
        "\n",
        "    def L(self, h: Tensor, h_e: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "       h**(Omega) * h_e**(1-Omega)\n",
        "        \"\"\"\n",
        "        h  = h.clamp_min(1e-12)\n",
        "        h_e = h_e.clamp_min(1e-12)\n",
        "        return h**(self.Omega) * h_e**(1-self.Omega)\n",
        "        \"\"\"\n",
        "# ---------- 5) the dynamics of net worth----------\n",
        "class V:\n",
        "    def __init__(self, w=0.9):\n",
        "        self.w = torch.tensor(w, dtype=torch.double)\n",
        "\n",
        "    def V(self,\n",
        "          Rk: Tensor,\n",
        "          q_t-1: Tensor,\n",
        "          K_t:Tensor,\n",
        "          N_t;Tensor,\n",
        "          ) -> Tensor:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ---------- 5) Planner: choose {m_t, h_t} to max Σ β^t u(c_t,h_t; N_t) ----------\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class PTPlanner:\n",
        "    def __init__(self, T=50, beta=0.96, lam=1.0):\n",
        "        self.T = T\n",
        "        self.beta = torch.tensor(beta, dtype=torch.double)\n",
        "        self.lam = lam\n",
        "\n",
        "        self.util = HouseholdUtility()\n",
        "        self.match = Matching()\n",
        "        self.ldyn = LaborDynamics(matching=self.match)\n",
        "        self.prod = Production()\n",
        "\n",
        "        self.N0 = torch.tensor([0.3, 0.3, 0.3], dtype=torch.double)  # 合計<=1を想定\n",
        "        self.z  = torch.tensor([1.0, 1.0, 1.0], dtype=torch.double)\n",
        "\n",
        "    # ←← この simulate をクラス内に入れてください（インプレース更新なし）\n",
        "    def simulate(self, M_free: torch.Tensor, H_free: torch.Tensor):\n",
        "        \"\"\"\n",
        "        決定変数（非負制約は softplus で表現）:\n",
        "          M_free: (T,3) → m_t >= 0\n",
        "          H_free: (T,3) → h_t >= 0\n",
        "        制約（雇用動学や資源制約）はこの中で前進シミュレーションとして満たす。\n",
        "        \"\"\"\n",
        "        device = M_free.device\n",
        "        m_t = F.softplus(M_free)  # (T,3)\n",
        "        h_t = F.softplus(H_free)  # (T,3)\n",
        "\n",
        "        N_list   = [self.N0.to(device)]\n",
        "        u_list   = []\n",
        "        x_list   = []\n",
        "        c_list   = []\n",
        "        u_agg_ls = []\n",
        "\n",
        "        for t in range(self.T):\n",
        "            N_prev = N_list[-1]                # (3,)\n",
        "            u_total = 1.0 - N_prev.sum()\n",
        "            share   = (N_prev / N_prev.sum().clamp_min(1e-12)).clamp_min(0.0)\n",
        "            u_vec   = u_total * share          # (3,)\n",
        "\n",
        "            x_t = self.prod.x(N_prev, self.z.to(device), h_t[t], m_t[t])  # (3,)\n",
        "            c_t = x_t                              # 簡略：生産=消費\n",
        "\n",
        "            u_t = self.util.u(c_t, h_t[t], N_prev, lam=self.lam)\n",
        "            N_next = self.ldyn.N_next(N_prev, m_t[t], u_vec)\n",
        "\n",
        "            u_list.append(u_vec)\n",
        "            x_list.append(x_t)\n",
        "            c_list.append(c_t)\n",
        "            u_agg_ls.append(u_t)\n",
        "            N_list.append(N_next)\n",
        "\n",
        "        N     = torch.stack(N_list,   dim=0)   # (T+1,3)\n",
        "        u_pool= torch.stack(u_list,   dim=0)   # (T,3)\n",
        "        x_out = torch.stack(x_list,   dim=0)   # (T,3)\n",
        "        c     = torch.stack(c_list,   dim=0)   # (T,3)\n",
        "        u_agg = torch.stack(u_agg_ls, dim=0)   # (T,)\n",
        "\n",
        "        betas = self.beta ** torch.arange(self.T, dtype=torch.double, device=device)\n",
        "        total_util = torch.sum(u_agg * betas)\n",
        "\n",
        "        return total_util, {\"N\": N, \"m\": m_t, \"h\": h_t, \"c\": c, \"x\": x_out, \"u_per_t\": u_agg, \"u_pool\": u_pool}\n",
        "\n",
        "    # ←← これが新規：クラス内の optimize（Adamで効用最大化）\n",
        "    def optimize(self, steps=1000, lr=1e-2, device=None):\n",
        "        device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        # 決定変数（自由パラメータ）を作って勾配対象に\n",
        "        M_free = torch.zeros((self.T, 3), dtype=torch.double, requires_grad=True, device=device)\n",
        "        H_free = torch.zeros((self.T, 3), dtype=torch.double, requires_grad=True, device=device)\n",
        "\n",
        "        # 参照テンソルも同じ device に\n",
        "        self.N0 = self.N0.to(device)\n",
        "        self.z  = self.z.to(device)\n",
        "\n",
        "        opt = torch.optim.Adam([M_free, H_free], lr=lr)\n",
        "\n",
        "        # （デバッグしたい場合は次の行のコメントを外す）\n",
        "        # torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "        for s in range(1, steps+1):\n",
        "            opt.zero_grad()\n",
        "            total_util, _ = self.simulate(M_free, H_free)  # 制約付き前進→目的\n",
        "            loss = -total_util                             # 最大化→最小化に反転\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            if s % 100 == 0:\n",
        "                print(f\"[step {s}] utility={float(total_util):.6f}\")\n",
        "\n",
        "        return M_free.detach(), H_free.detach()\n"
      ]
    }
  ]
}